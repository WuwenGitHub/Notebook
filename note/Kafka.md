# 介绍  一个**分布式流处理**平台  1.流处理平台特性     * 发布和订阅流式的记录     * 储存流式的记录，并且有较好的容错性     * 在流式记录产生时就进行处理  2.两大类别的应用     * 构造实时数据流管道     * 构建实时流式应用程序3.相关概念     * **集群**，运行在一台或多台服务器上   * 通过*topic*对存储的流数据进行分类   * 每条记录中包含一个*key*，一个*value*，一个时间戳*timestamp*4.四个核心API   * Producer API      * 允许一个应用程序发布一串流式的数据到**一个或多个**Kafka topic   * Consumer API      * 允许一个应用程序订阅**一个或多个***topic*，并且对发布给他们的流式数据进行处理   * Streams API      * 允许一个应用程序作为一个*流处理器*，消费**一个或多个***topic*产生的输入流，然后产生**一个**      输出流到**一个或多个***topic*中去，在**输入输出流**中进行有效的转换   * Connector API      * 允许构建并运行**可重用**的生产者和消费者，将*Kafka topic*连接到**已存在**的应用程序和数据系统。![kafka api](../pics/kafka-apis.png "Kafka API")   注：在kafka中，客户端和服务器使用一个简单、高性能、支持多语言的**TCP协议**。（此协议版本化并向下兼容老版本）# Topics和日志  1.Kafka核心概念  提供一串流式的记录--topic2.Topic   * 数据记录发布的地方   * 可用于区分业务系统   * 多订阅者模式   * 每一个topic --> 一个分区日志 3.分区及日志   * 记录集   * 有序且顺序不可变      * 仅保证该分区中的记录有序，不保证主题中不同分区间的顺序   * 结构化的commit log文件   * offset      * 用于表示顺序      * 唯一标识分区中的每一条记录，等同于id      * 消费者唯一保存的元数据   * 保留所有发布的记录      * 保留期限   * 分区用途      * 当日志大小超过了单台服务器的限制，允许日志进行扩展         * 一个主题可能存在多个分区      * 可作为并行的单元集# 分布式1.日志的分区partition分布 -- Kafka集群的服务器上2.分区的共享 -- 每个服务器对数据处理和请求3.容错性 -- 每一个分区在已配置的服务器上对日志进行备份4.分区中的leader和follwers   * leader -- 一台server  -- 处理一切对partition的读写请求   * follwer -- 零或多台server -- 被动同步leader上的数据   * leader宕机 -- follwers中的一台成为新的leader   * leader -- 某些分区的leader及某些分区的follwers -- 达到负载均衡# 生产着     * 将记录分配到topic的哪一个partition中   * 负载均衡      1. 循环方式      2. 某些语义分区函数# 消费者     * 标识方式 -- *消费组*   * topic中记录与消费者之间关系      * 一条记录 --> 消费组中的一个消费者实例   * 消费者实例分布      * 多进程或多机器上   * 消息记录与消费者间关系      * 所有消费者实例在同一消费组中 --> 负载平衡到每一个消费者实例      * 于不同消费组中 --> 广播到所有的消费者进程        ![kafka api](../pics/consumer-groups.png "Kafka API")# 保证     * 生产者发送到特定topic partition 的消息将按照发送的顺序处理   * 一个消费者实例按照日志中的顺序查看记录   * 对于具有N个副本的主题，我们最多容忍N-1个服务器故障，从而保证不会丢失任何提交到日志中的记录